{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import skbio\n",
    "\n",
    "from itertools import combinations\n",
    "from multiprocessing import Pool\n",
    "from skbio import TreeNode\n",
    "from skbio.diversity.alpha import faith_pd\n",
    "from skbio.diversity.beta import unweighted_unifrac, weighted_unifrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables go in all caps\n",
    "MYBIOM = pd.read_table('./data/updated_lacto_sum_scaled.tsv')\n",
    "MYTREE = skbio.read('./data/tree.nwk', format='newick', into=TreeNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_IDS = MYBIOM.columns[1:]\n",
    "OTU_IDS = MYBIOM['asv']\n",
    "NCORES = 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Diversity\n",
    "To calculate the Faith's PD for each of the samples, we must iterate over each of the feature table's columns, extract that column, pass that column into the `faith_pd` function, and then save that output to a list.\n",
    "\n",
    "This could be accomplished like so:\n",
    "\n",
    "```python\n",
    "alpha_list = []\n",
    "for i in SAMPLE_IDS:\n",
    "    sample = MYBIOM[sample_id]\n",
    "    tmp = faith_pd(sample, otu_ids=OTU_IDS, tree=MYTREE)\n",
    "    alpha_list.append(tmp)\n",
    "```\n",
    "\n",
    "This function is slow, but this is an easy problem to parallelize. To do so, we will use the `multiprocessing` library's `Pool` object.\n",
    "This will allow us to create a pool of processes and throw it at this problem via `Pool.map()`. `map()` accepts a function (`faith_pd()`) and an iterable\n",
    "(our sample vectors).\n",
    "In this case, our function `faith_pd()` requires additional arguments so we need to do some wrangling before we can just pop it into `Pool.map()`.\n",
    "We can accomplish this by using `partial()` or by creating a wrapper function that accepts the column name and then performs the `faith_pd()` calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faith_fun(sample_id):\n",
    "    # to avoid doing \"partial\" nonsense, we wrap the faith_pd\n",
    "    # function in another function so we can reference the \n",
    "    # global OTU_IDS and MYTREE variables.\n",
    "\n",
    "    # get the column for the given sample_id\n",
    "    sample = MYBIOM[sample_id]\n",
    "    # run faith_pd on sample\n",
    "    alpha = faith_pd(sample, otu_ids=OTU_IDS, tree=MYTREE)\n",
    "\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sampleid   faith_pd\n",
      "0  1_0403_9699  41.863220\n",
      "1  1_0410_9686  47.256110\n",
      "2  1_0410_9687  39.344774\n",
      "3  1_0410_9689  44.571748\n",
      "4  1_0410_9691  40.486682\n"
     ]
    }
   ],
   "source": [
    "# use the \"with x as y:\" syntax so we don't have to close\n",
    "# our Pool manually. It's good to tidy up\n",
    "with Pool(NCORES) as p:\n",
    "    alphas = p.map(faith_fun, SAMPLE_IDS)\n",
    "\n",
    "# convert to dataframe for export\n",
    "alphas = pd.DataFrame({'sampleid' : SAMPLE_IDS,\n",
    "                       'faith_pd' : alphas})\n",
    "\n",
    "print(alphas.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta Diversity\n",
    "This code is very inefficient as we populate the entire symmetric distance matrix instead of just the lower triangle. It would be better to instead pass the list of combinations to the `Pool.map()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unweighted_unifrac_fun_slow(sample_id):\n",
    "    # return all unweighted unifrac distances\n",
    "    # for a given sample_id (u)\n",
    "\n",
    "    u = MYBIOM[sample_id]\n",
    "    beta_list = []\n",
    "    # iterate over all samples (v) and compare them to u\n",
    "    for v_id in SAMPLE_IDS:\n",
    "        # skip expensive calculations if self to self comparison\n",
    "        if sample_id == v_id:\n",
    "            beta_list.append(0)\n",
    "        else:\n",
    "            v = MYBIOM[v_id]\n",
    "            beta = unweighted_unifrac(u, v, tree=MYTREE,\n",
    "                                      otu_ids=OTU_IDS, validate=False)\n",
    "            beta_list.append(beta)\n",
    "        \n",
    "    return beta_list\n",
    "\n",
    "with Pool(NCORES) as p:\n",
    "    uw_betas = p.map(unweighted_unifrac_fun_slow, SAMPLE_IDS)\n",
    "\n",
    "uw = pd.DataFrame(uw_betas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By instead using `itertool`'s `combinations` function, we instead only pass the unique pairs of u,v and we reduce our computational workload by over a factor of 2. The code is also more straightforward and compact. Unfortunately, this is still slower than molasses. The `unifrac` library is a Godsend. Use that instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unweighted_unifrac_fun_fast(combs: tuple):\n",
    "    # accepts a tuple of (u, v)\n",
    "    u = MYBIOM[combs[0]]\n",
    "    v = MYBIOM[combs[1]]\n",
    "\n",
    "    beta = unweighted_unifrac(u, v, tree=MYTREE,\n",
    "                              otu_ids=OTU_IDS, validate=False)\n",
    "    \n",
    "    return(beta)\n",
    "\n",
    "# combinations will create all combinations of size n from a given iterable.\n",
    "with Pool(NCORES) as p:\n",
    "    uw_betas = p.map(unweighted_unifrac_fun_fast, combinations(SAMPLE_IDS, 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-2022.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
